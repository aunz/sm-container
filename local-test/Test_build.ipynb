{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the build and running of containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sm-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  417.8kB\n",
      "Step 1/12 : FROM python:3.7\n",
      " ---> 8e3336637d81\n",
      "Step 2/12 : ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1 PYTHONIOENCODING=UTF-8 LANG=C.UTF-8 LC_ALL=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> cda7dc370c61\n",
      "Step 3/12 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 1bab301534e5\n",
      "Step 4/12 : RUN apt update # 17.4MB\n",
      " ---> Using cache\n",
      " ---> 99d3220a9dac\n",
      "Step 5/12 : RUN pip install flask # 26.8MB\n",
      " ---> Using cache\n",
      " ---> 0076d0b6a6e5\n",
      "Step 6/12 : RUN pip install boto3 # 84.2MB\n",
      " ---> Using cache\n",
      " ---> d3544692a54a\n",
      "Step 7/12 : RUN pip install pandas scikit-learn # 392MB\n",
      " ---> Using cache\n",
      " ---> 69ac9f4f8895\n",
      "Step 8/12 : RUN rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> e44fa9a2385b\n",
      "Step 9/12 : ENV FLASK_ENV=production FLASK_APP=/opt/program/wsgi FLASK_RUN_HOST=0.0.0.0 FLASK_RUN_PORT=8080\n",
      " ---> Using cache\n",
      " ---> 0678e52fb8b0\n",
      "Step 10/12 : COPY program /opt/program/\n",
      " ---> 4bc5f3aa41f3\n",
      "Step 11/12 : WORKDIR /opt/program\n",
      " ---> Running in 8f0d5c58cf60\n",
      "Removing intermediate container 8f0d5c58cf60\n",
      " ---> 234f9d0fc8fa\n",
      "Step 12/12 : RUN chmod +x /opt/program/serve\n",
      " ---> Running in 39a589be59b4\n",
      "Removing intermediate container 39a589be59b4\n",
      " ---> 0ab16925eb2c\n",
      "Successfully built 0ab16925eb2c\n",
      "Successfully tagged sm-base:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -f ../Dockerfile.base -t sm-base .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.7\n",
      "1.18.2 1.0.3 1.4.1 0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run --rm sm-base python --version\n",
    "docker run --rm sm-base python -c \"import numpy, pandas, scipy, sklearn; print(numpy.__version__, pandas.__version__, scipy.__version__, sklearn.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper script for testing\n",
    "\n",
    "/tmp/test-build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile docker-compose.yml\n",
    "# version: '2.0'\n",
    "# services:\n",
    "#   web:\n",
    "#     image: sm-base\n",
    "#     ports:\n",
    "#     - \"8080:8080\"\n",
    "#     volumes:\n",
    "#     - /dev/shm/userpackage:/opt/program/userpackage\n",
    "#     environment:\n",
    "#     - SAGEMAKER_PROGRAM=entry.py\n",
    "#     - PRINT_SYS=1\n",
    "#     entrypoint: serve\n",
    "\n",
    "# !docker-compose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/test-build.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/test-build.sh\n",
    "#!/bin/bash\n",
    "container=$1\n",
    "data=$2\n",
    "s=${3:-'6'} # sleep time before issuing http request\n",
    "SAGEMAKER_PROGRAM=${SAGEMAKER_PROGRAM:-\"entry.py\"}\n",
    "PRINT_SYS=${PRINT_SYS:-\"1\"}\n",
    "\n",
    "if [[ $PRINT_SYS == '-1' ]]; then PRINT_SYS=''; fi\n",
    "\n",
    "\n",
    "function init_serve() {\n",
    "    docker run --rm \\\n",
    "      -v /dev/shm/userpackage:/opt/program/userpackage \\\n",
    "      -p 8080:8080 \\\n",
    "      -e SAGEMAKER_PROGRAM=$SAGEMAKER_PROGRAM \\\n",
    "      -e PRINT_SYS=$PRINT_SYS \\\n",
    "      --name test \\\n",
    "    $container serve\n",
    "}\n",
    "\n",
    "# make the ping and invocation request\n",
    "function req() {\n",
    "    sleep $s # need to sleep a bit for the server to start up\n",
    "    echo ping\n",
    "    curl localhost:8080/ping\n",
    "    echo invocations\n",
    "    curl --data \"$data\" localhost:8080/invocations\n",
    "}\n",
    "\n",
    "# finally kill the container\n",
    "function k() {\n",
    "    sleep $((s + 1))\n",
    "#     docker rm -f test\n",
    "    docker rm -f $(docker ps -aq)\n",
    "}\n",
    "\n",
    "req & k & init_serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "d='/dev/shm/userpackage/'\n",
    "rm -rf $d\n",
    "mkdir -p $d\"insect/hymenoptera/ant\"\n",
    "mkdir -p $d\"insect/hymenoptera/bee\"\n",
    "mkdir -p $d\"insect/lepidoptera/butterfly\"\n",
    "mkdir -p $d\"crustacean/nephropoidea/lobster\"\n",
    "\n",
    "cd $d\n",
    "echo -e \"print('Phylum arthropod')\" > arthropod.py\n",
    "echo -e \"print('insect init')\" > insect/__init__.py\n",
    "echo -e \"print('red ant'); from . import black\" > insect/hymenoptera/ant/red.py\n",
    "echo -e \"print('black ant'); from ..bee import bumble\" > insect/hymenoptera/ant/black.py\n",
    "echo -e \"print('bumble bee'); from ...lepidoptera.butterfly import monarch\" > insect/hymenoptera/bee/bumble.py\n",
    "echo -e \"print('monarch butterfly');\n",
    "import os;\n",
    "path = os.path.dirname(__file__) + '/monarch.txt'\n",
    "print(open(path).read())\n",
    "\n",
    "path = os.path.dirname(__file__)\n",
    "path = os.path.join(path, '../../..', 'crustacean/nephropoidea/lobster/lobster.txt')\n",
    "print(open(path).read())\"> insect/lepidoptera/butterfly/monarch.py\n",
    "\n",
    "echo -e \"monarchs migrate\" > insect/lepidoptera/butterfly/monarch.txt\n",
    "echo -e \"lobsters scavenge\" > crustacean/nephropoidea/lobster/lobster.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /dev/shm/userpackage/entry.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dev/shm/userpackage/entry.py\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "print(f'''\n",
    "User entry point\n",
    "numpy: {numpy.__version__}\n",
    "pandas: {pandas.__version__}\n",
    "scipy: {scipy.__version__}\n",
    "{__file__}\n",
    "dirname: {os.path.dirname(__file__)}\n",
    "os.getcwd: {os.getcwd()}\n",
    "''')\n",
    "\n",
    "if __name__== '__main__':\n",
    "    print('Main')\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print('model_fn called', model_dir)\n",
    "    \n",
    "def transform_fn(input_data, model):\n",
    "    print('transform_fn called', input_data, model)\n",
    "    return input_data\n",
    "\n",
    "from . import arthropod\n",
    "from .insect.hymenoptera.ant import red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "User entry point\r\n",
      "numpy: 1.14.3\r\n",
      "pandas: 0.24.2\r\n",
      "scipy: 1.1.0\r\n",
      "/dev/shm/userpackage/entry.py\r\n",
      "dirname: /dev/shm/userpackage\r\n",
      "os.getcwd: /dev/shm\r\n",
      "\r\n",
      "Phylum arthropod\r\n",
      "insect init\r\n",
      "red ant\r\n",
      "black ant\r\n",
      "bumble bee\r\n",
      "monarch butterfly\r\n",
      "monarchs migrate\r\n",
      "\r\n",
      "lobsters scavenge\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# can run the entry.py as a package locally \n",
    "!cd /dev/shm && python -c 'import userpackage.entry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start SERVE\n",
      "environ({'PATH': '/opt/program:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin', 'HOSTNAME': 'eb02ece9a1e3', 'SAGEMAKER_PROGRAM': 'entry.py', 'PRINT_SYS': '1', 'LANG': 'C.UTF-8', 'GPG_KEY': '0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D', 'PYTHON_VERSION': '3.7.7', 'PYTHON_PIP_VERSION': '20.0.2', 'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/d59197a3c169cef378a22428a3fa99d33e080a5d/get-pip.py', 'PYTHON_GET_PIP_SHA256': '421ac1d44c0cf9730a088e337867d974b91bdce4ea2636099275071878cc189e', 'PYTHONDONTWRITEBYTECODE': '1', 'PYTHONUNBUFFERED': '1', 'PYTHONIOENCODING': 'UTF-8', 'LC_ALL': 'C.UTF-8', 'FLASK_ENV': 'production', 'FLASK_APP': '/opt/program/wsgi', 'FLASK_RUN_HOST': '0.0.0.0', 'FLASK_RUN_PORT': '8080', 'HOME': '/root'})\n",
      "pip freeze\n",
      "boto3==1.12.26\n",
      "botocore==1.15.26\n",
      "click==7.1.1\n",
      "docutils==0.15.2\n",
      "Flask==1.1.1\n",
      "itsdangerous==1.1.0\n",
      "Jinja2==2.11.1\n",
      "jmespath==0.9.5\n",
      "joblib==0.14.1\n",
      "MarkupSafe==1.1.1\n",
      "numpy==1.18.2\n",
      "pandas==1.0.3\n",
      "python-dateutil==2.8.1\n",
      "pytz==2019.3\n",
      "s3transfer==0.3.3\n",
      "scikit-learn==0.22.2.post1\n",
      "scipy==1.4.1\n",
      "six==1.14.0\n",
      "urllib3==1.25.8\n",
      "Werkzeug==1.0.0\n",
      "df -h\n",
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         109G   83G   26G  76% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           2.0G     0  2.0G   0% /sys/fs/cgroup\n",
      "/dev/xvda1      109G   83G   26G  76% /etc/hosts\n",
      "shm              64M     0   64M   0% /dev/shm\n",
      "tmpfs           2.0G  100K  2.0G   1% /opt/program/userpackage\n",
      "tmpfs           2.0G     0  2.0G   0% /proc/acpi\n",
      "tmpfs           2.0G     0  2.0G   0% /proc/scsi\n",
      "tmpfs           2.0G     0  2.0G   0% /sys/firmware\n",
      "free -h\n",
      "              total        used        free      shared  buff/cache   available\n",
      "Mem:          3.9Gi       517Mi       1.1Gi       0.0Ki       2.2Gi       3.1Gi\n",
      "Swap:            0B          0B          0B\n",
      "dir tree\n",
      "/opt\n",
      " |-\u0001rogram\n",
      " | |-\u0001etup.py\n",
      " | |-\u0001ginx.conf\n",
      " | |-\u0001redictor.py\n",
      " | |-\u0001erve\n",
      " | |-\u0001sgi.py\n",
      " | |-\u0001rain\n",
      " | |-\u0001erve2\n",
      " | |-\u0001ANIFEST.in\n",
      " | |-\u0001serpackage\n",
      " | | |-\u0001odel.h5\n",
      " | | |-\u0001ntry_tf.py\n",
      " | | |-\u0001_pycache__\n",
      " | | | |-\u0001rthropod.cpython-36.pyc\n",
      " | | | |-\u0001ntry.cpython-36.pyc\n",
      " | | |-\u0001ntry.py\n",
      " | | |-\u0001rthropod.py\n",
      " | | |-\u0001rustacean\n",
      " | | | |-\u0001ephropoidea\n",
      " | | | | |-\u0001obster\n",
      " | | | | | |-\u0001obster.txt\n",
      " | | |-\u0001nsect\n",
      " | | | |-\u0001_pycache__\n",
      " | | | | |-\u0001_init__.cpython-36.pyc\n",
      " | | | |-\u0001_init__.py\n",
      " | | | |-\u0001epidoptera\n",
      " | | | | |-\u0001utterfly\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001onarch.cpython-36.pyc\n",
      " | | | | | |-\u0001onarch.txt\n",
      " | | | | | |-\u0001onarch.py\n",
      " | | | |-\u0001ymenoptera\n",
      " | | | | |-\u0001ee\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001umble.cpython-36.pyc\n",
      " | | | | | |-\u0001umble.py\n",
      " | | | | |-\u0001nt\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001lack.cpython-36.pyc\n",
      " | | | | | | |-\u0001ed.cpython-36.pyc\n",
      " | | | | | |-\u0001lack.py\n",
      " | | | | | |-\u0001ed.py\n",
      "entry.py\n",
      "None\n",
      "Processing /opt/program\n",
      "Building wheels for collected packages: userpackage\n",
      "  Building wheel for userpackage (setup.py): started\n",
      "  Building wheel for userpackage (setup.py): finished with status 'done'\n",
      "  Created wheel for userpackage: filename=userpackage-0.0.0-py3-none-any.whl size=10380 sha256=c967632dcdc2307c17fc09bba5c9e3a884c8007024634133c2fd4fd8c8f52dbf\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-6r6shhse/wheels/ee/2b/78/e3215510865583a7fcd2b959c2c60d49aa4d00d1a3171f6744\n",
      "Successfully built userpackage\n",
      "Installing collected packages: userpackage\n",
      "Successfully installed userpackage-0.0.0\n",
      "dir tree\n",
      "/opt\n",
      " |-\u0001rogram\n",
      " | |-\u0001etup.py\n",
      " | |-\u0001ginx.conf\n",
      " | |-\u0001redictor.py\n",
      " | |-\u0001erve\n",
      " | |-\u0001sgi.py\n",
      " | |-\u0001rain\n",
      " | |-\u0001erve2\n",
      " | |-\u0001ANIFEST.in\n",
      " | |-\u0001serpackage\n",
      " | | |-\u0001odel.h5\n",
      " | | |-\u0001ntry_tf.py\n",
      " | | |-\u0001_pycache__\n",
      " | | | |-\u0001rthropod.cpython-36.pyc\n",
      " | | | |-\u0001ntry.cpython-36.pyc\n",
      " | | |-\u0001ntry.py\n",
      " | | |-\u0001rthropod.py\n",
      " | | |-\u0001rustacean\n",
      " | | | |-\u0001ephropoidea\n",
      " | | | | |-\u0001obster\n",
      " | | | | | |-\u0001obster.txt\n",
      " | | |-\u0001nsect\n",
      " | | | |-\u0001_pycache__\n",
      " | | | | |-\u0001_init__.cpython-36.pyc\n",
      " | | | |-\u0001_init__.py\n",
      " | | | |-\u0001epidoptera\n",
      " | | | | |-\u0001utterfly\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001onarch.cpython-36.pyc\n",
      " | | | | | |-\u0001onarch.txt\n",
      " | | | | | |-\u0001onarch.py\n",
      " | | | |-\u0001ymenoptera\n",
      " | | | | |-\u0001ee\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001umble.cpython-36.pyc\n",
      " | | | | | |-\u0001umble.py\n",
      " | | | | |-\u0001nt\n",
      " | | | | | |-\u0001_pycache__\n",
      " | | | | | | |-\u0001lack.cpython-36.pyc\n",
      " | | | | | | |-\u0001ed.cpython-36.pyc\n",
      " | | | | | |-\u0001lack.py\n",
      " | | | | | |-\u0001ed.py\n",
      "\n",
      "User entry point\n",
      "numpy: 1.18.2\n",
      "pandas: 1.0.3\n",
      "scipy: 1.4.1\n",
      "/opt/program/userpackage/entry.py\n",
      "dirname: /opt/program/userpackage\n",
      "os.getcwd: /opt/program\n",
      "\n",
      "Phylum arthropod\n",
      "insect init\n",
      "red ant\n",
      "black ant\n",
      "bumble bee\n",
      "monarch butterfly\n",
      "monarchs migrate\n",
      "\n",
      "lobsters scavenge\n",
      "\n",
      "model_fn called /opt/ml/model/\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "ping\n",
      "172.17.0.1 - - [23/Mar/2020 19:37:34] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n",
      "\n",
      "invocations\n",
      "transform_fn called b'blah blah 13608' None\n",
      "172.17.0.1 - - [23/Mar/2020 19:37:34] \"\u001b[37mPOST /invocations HTTP/1.1\u001b[0m\" 200 -\n",
      "blah blah 13608test\n"
     ]
    }
   ],
   "source": [
    "!bash /tmp/test-build.sh sm-base \"blah blah $RANDOM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sm-xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  376.8kB\n",
      "Step 1/3 : FROM sm-base\n",
      " ---> acb099b9a6e0\n",
      "Step 2/3 : RUN pip install xgboost\n",
      " ---> Running in bf7043003eac\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.0.2-py3-none-manylinux1_x86_64.whl (109.7 MB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from xgboost) (1.18.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.2\n",
      "Removing intermediate container bf7043003eac\n",
      " ---> e0074bf22128\n",
      "Step 3/3 : RUN rm -rf /root/.cache\n",
      " ---> Running in 2913ecb692e4\n",
      "Removing intermediate container 2913ecb692e4\n",
      " ---> bef5825a5c61\n",
      "Successfully built bef5825a5c61\n",
      "Successfully tagged sm-xgb:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -f ../Dockerfile.xgb -t sm-xgb .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!docker run --rm sm-xgb python -c \"import xgboost; print(xgboost.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sm-tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  417.8kB\n",
      "Step 1/3 : FROM sm-base\n",
      " ---> 0ab16925eb2c\n",
      "Step 2/3 : RUN pip install tensorflow\n",
      " ---> Running in e9e903822997\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.14.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting gast==0.2.2\n",
      "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Downloading grpcio-1.27.2-cp37-cp37m-manylinux2010_x86_64.whl (2.7 MB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.34.2)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.18.2)\n",
      "Collecting keras-preprocessing>=1.1.0\n",
      "  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "  Downloading tensorboard-2.1.1-py3-none-any.whl (3.8 MB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "  Downloading tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448 kB)\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (46.0.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.2.1-py2.py3-none-any.whl (88 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.11.3-py2.py3-none-any.whl (76 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.23.0-py2.py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Downloading rsa-4.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.0.0-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
      "Collecting chardet<4,>=3.0.2\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.9-py2.py3-none-any.whl (58 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: gast, termcolor, wrapt, absl-py\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=bfad57d9b20fb78823b1783bc3de4cd569076189a22171c53a9375ce16a11b3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=345b3ee4764f59f3db24cc569c0ab7a488991e4d58bb65a85f68f62f25fa4319\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=76427 sha256=5f5f6d8e8124ccb1655108c96a550399c8bf8c7bba6dbdcd4bbdae2317e752ec\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121931 sha256=427ee02d1a5214d3a03cf97f0d63194c2c1e98dd621c94ccb2f3941c9e7aa29e\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n",
      "Successfully built gast termcolor wrapt absl-py\n",
      "Installing collected packages: astor, opt-einsum, gast, termcolor, grpcio, wrapt, protobuf, keras-preprocessing, google-pasta, markdown, absl-py, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, certifi, chardet, idna, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow-estimator, h5py, keras-applications, tensorflow\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 certifi-2019.11.28 chardet-3.0.4 gast-0.2.2 google-auth-1.11.3 google-auth-oauthlib-0.4.1 google-pasta-0.2.0 grpcio-1.27.2 h5py-2.10.0 idna-2.9 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 oauthlib-3.1.0 opt-einsum-3.2.0 protobuf-3.11.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.23.0 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 termcolor-1.1.0 wrapt-1.12.1\n",
      "Removing intermediate container e9e903822997\n",
      " ---> 3b4a97f2025e\n",
      "Step 3/3 : RUN rm -rf /root/.cache\n",
      " ---> Running in fe8deb12fd7f\n",
      "Removing intermediate container fe8deb12fd7f\n",
      " ---> 9b4cf30c01e9\n",
      "Successfully built 9b4cf30c01e9\n",
      "Successfully tagged sm-tf:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -f ../Dockerfile.tf -t sm-tf .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Can run sm-tf. Ignore the warning messages about CPU, GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "##### tf.Tensor(-609.01776, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-23 19:20:22.789262: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:20:22.789424: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:20:22.789443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-03-23 19:20:24.389861: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:20:24.389900: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-03-23 19:20:24.389927: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (4f407e43345a): /proc/driver/nvidia/version does not exist\n",
      "2020-03-23 19:20:24.390353: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-23 19:20:24.397646: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400040000 Hz\n",
      "2020-03-23 19:20:24.397865: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562cf787eed0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-23 19:20:24.397887: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "docker run --rm sm-tf python -c \"\n",
    "import tensorflow as tf;\n",
    "print(tf.__version__);\n",
    "print('#####', tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /dev/shm/userpackage/entry_tf.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /dev/shm/userpackage/entry_tf.py\n",
    "import os\n",
    "import numpy\n",
    "import pandas\n",
    "import scipy\n",
    "import sklearn\n",
    "import tensorflow\n",
    "\n",
    "print(f'''\n",
    "User entry point\n",
    "numpy: {numpy.__version__}\n",
    "pandas: {pandas.__version__}\n",
    "scipy: {scipy.__version__}\n",
    "sklearn: {sklearn.__version__}\n",
    "tf: {tensorflow.__version__}\n",
    "{__file__}\n",
    "dirname: {os.path.dirname(__file__)}\n",
    "os.getcwd: {os.getcwd()}\n",
    "''')\n",
    "\n",
    "\n",
    "#### Some testing ###\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "n = 6000 # rows\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.rand(n, 2) * np.random.choice([-1, 1], (n, 2))\n",
    "y = 3 + 10 * X[:,0] + 20 * X[:,1] + np.random.rand(n) * np.random.choice([-1, 1], n)\n",
    "\n",
    "# split into train and test\n",
    "split = 5000\n",
    "X_train, X_val = X[:split,], X[split:,]\n",
    "y_train, y_val = y[:split,], y[split:,]\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(4, input_dim=2, activation='sigmoid'))\n",
    "model.add(tf.keras.layers.Dense(2, activation='linear'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1, verbose=2)\n",
    "\n",
    "print('\\n###### Training completed #####')\n",
    "subprocess.run(['mkdir', '-p', '/opt/ml/model'])\n",
    "model.save('/opt/ml/model/model.h5')\n",
    "print('\\n###### Model saved #####')\n",
    "\n",
    "print(((model.predict(X_val).flatten() - y_val) ** 2).mean() ** 0.5)\n",
    "\n",
    "###### the inference part ##########\n",
    "\n",
    "if __name__== '__main__':\n",
    "    print('Main')\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    print('model_fn called', model_dir)\n",
    "    m = tf.keras.models.load_model(model_dir + 'model.h5')\n",
    "    print('Model loaded')\n",
    "    return m\n",
    "    \n",
    "    \n",
    "def transform_fn(input_data, model):\n",
    "    print('transform_fn called', input_data, model)\n",
    "    tmp = json.loads(input_data)\n",
    "    tmp = np.array(tmp)\n",
    "    tmp = model.predict(tmp)\n",
    "    print('the predicted', tmp)\n",
    "    return np.array2string(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start SERVE\n",
      "2020-03-23 19:37:04.342680: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:37:04.342996: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:37:04.343022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "User entry point\n",
      "numpy: 1.18.2\n",
      "pandas: 1.0.3\n",
      "scipy: 1.4.1\n",
      "sklearn: 0.22.2.post1\n",
      "tf: 2.1.0\n",
      "/opt/program/userpackage/entry_tf.py\n",
      "dirname: /opt/program/userpackage\n",
      "os.getcwd: /opt/program\n",
      "\n",
      "2020-03-23 19:37:04.979118: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-03-23 19:37:04.979159: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-03-23 19:37:04.979185: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5fe7b4aa2204): /proc/driver/nvidia/version does not exist\n",
      "2020-03-23 19:37:04.979382: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-23 19:37:04.985752: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400040000 Hz\n",
      "2020-03-23 19:37:04.986017: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bb031ebd20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-23 19:37:04.986165: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Train on 5000 samples\n",
      "5000/5000 - 1s - loss: 163.1534 - mae: 10.7109\n",
      "\n",
      "\n",
      "###### Training completed #####\n",
      "\n",
      "\n",
      "###### Model saved #####\n",
      "12.664268153977414\n",
      "model_fn called /opt/ml/model/\n",
      "Model loaded\n",
      " * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit)\n",
      "ping\n",
      "172.17.0.1 - - [23/Mar/2020 19:37:14] \"\u001b[37mGET /ping HTTP/1.1\u001b[0m\" 200 -\n",
      "\n",
      "invocations\n",
      "transform_fn called b'[[1, 2], [3, 4]]' <tensorflow.python.keras.engine.sequential.Sequential object at 0x7f06a80106d0>\n",
      "the predicted [[2.1863344]\n",
      " [2.3243597]]\n",
      "172.17.0.1 - - [23/Mar/2020 19:37:14] \"\u001b[37mPOST /invocations HTTP/1.1\u001b[0m\" 200 -\n",
      "[[2.1863344]\n",
      " [2.3243597]]test\n"
     ]
    }
   ],
   "source": [
    "!PRINT_SYS=\"-1\" SAGEMAKER_PROGRAM=\"entry_tf.py\" bash /tmp/test-build.sh sm-tf \"[[1, 2], [3, 4]]\" 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
